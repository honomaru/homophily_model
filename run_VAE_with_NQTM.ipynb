{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd853de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.tensor as T\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from NQTM_torch import NQTM\n",
    "from short_text_vae import Model\n",
    "import config_911 as config\n",
    "from components import *\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9526c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータ\n",
    "file_number = 1\n",
    "device = torch.device(f'cuda:{file_number}')\n",
    "config.learning_rate = 0.002\n",
    "config.topic_num = 6\n",
    "config.epoch_num = 60\n",
    "batch_size = 64\n",
    "K_d = 0.1\n",
    "parent_dir = '/mnt/NAS0CAC8A/h-mukai'\n",
    "fpath = '/mnt/NAS0CAC8A/h-mukai/NQTM/learning_'+str(file_number)+'.csv'#学習過程保存csv\n",
    "#kl_min = 1.\n",
    "#kl_t_n = 1600000\n",
    "#kl_s_n = 480000\n",
    "#tau_min = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69238947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力言語の語彙数： 5119\n"
     ]
    }
   ],
   "source": [
    "PAD_TOKEN = '<pad>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n",
    "BOS_TOKEN = '<s>'  # 系列の始まりを表す （Beggining of sentence）\n",
    "EOS_TOKEN = '</s>'  # 系列の終わりを表す （End of sentence）\n",
    "UNK_TOKEN = '<unk>'  # 語彙に存在しない単語を表す （Unknown）\n",
    "\n",
    "MIN_COUNT = 5  # 語彙に含める単語の最低出現回数\n",
    "PAD = 0\n",
    "# 単語をIDに変換する辞書の初期値を設定\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: 1,\n",
    "    EOS_TOKEN: 2,\n",
    "    UNK_TOKEN: 3,\n",
    "    }\n",
    "# 単語辞書を作成(seqのtrain入力を使う)\n",
    "vocab_X = Vocab(word2id=word2id)\n",
    "vocab_X.build_vocab(X_train_seq, min_count=MIN_COUNT)#Validも含めたじしょ\n",
    "vocab_size_X = len(vocab_X.id2word)\n",
    "print('入力言語の語彙数：', vocab_size_X)\n",
    "\n",
    "#IDへの変換\n",
    "train_id = [sentence_to_ids(vocab_X, sentence) for sentence in train_data]\n",
    "train_id_target = [sentence_to_ids(vocab_X, sentence) for sentence in train_data_t]\n",
    "word2id = vocab_X.word2id\n",
    "id2word = vocab_X.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217d6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwordsの含まれるor1文字以下のものは0カウント\n",
    "#discriminator時にもこの処理が必要かな\n",
    "from nltk.corpus import stopwords\n",
    "sw =  stopwords.words('english')\n",
    "sw += ['amp;','&amp;',\"there's\",\"this's\",\"that's\",'N%','N.','ht…','w','to…','f…','o…','yes','Nst',\"i've\",\"i'll\",'th…','N/N','a…','like','new',\"i'm\",'N',\"can't\",'many',\"he's\",\n",
    "          'could','need','would','people','one','still','may','might','<unk>','<pad>','<s>','</s>','N,N','.',\",\" \"''\",\"'s\", ':', \"'m\", \"'re\"] \n",
    "#mask行列を作る\n",
    "indices = []\n",
    "for w,i in word2id.items():\n",
    "    if w in sw or len(w)<=1:\n",
    "        indices.append(word2id[w])\n",
    "indices = T(indices)\n",
    "mask = torch.sum(F.one_hot(indices, vocab_size_X),0)\n",
    "mask = (torch.ones(vocab_size_X) - mask).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f5188bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データローダー\n",
    "train_dataloader = DataLoader(train_id, train_id_target, batch_size, device, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d09aeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_coef(step,n=20000):\n",
    "    return min(1., step/n)\n",
    "def print_top_words(beta, feature_names, n_top_words):\n",
    "    top_words = list()\n",
    "    for i in range(len(beta)):\n",
    "        top_words.append(\" \".join([feature_names[j] for j in beta[i].argsort()[:-n_top_words - 1:-1]]))\n",
    "        print(top_words[-1])\n",
    "\n",
    "def train(model, dataloader, config, optimizer,n):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for epoch in range(config.epoch_num):\n",
    "        w_omega = 0 if epoch < config.word_sample_epoch else 1.0\n",
    "        train_loss = list()\n",
    "        for batch in train_dataloader:\n",
    "            inputs, targets, lengths = batch\n",
    "            inputs = inputs.to(device);targets = targets.to(device);lengths = lengths.to(device)\n",
    "            K_kl = kl_coef(step)\n",
    "            tau = max(2 - step*(2/(len(X_train_seq)/16)/20),0.5)\n",
    "            kl_s, mle_loss, loss_topic, loss_d = model(inputs, lengths, w_omega, targets, tau)\n",
    "            loss = K_kl*kl_s+mle_loss+loss_topic+K_d*loss_d\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()#誤差伝搬(loss合計)\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.to('cpu').detach())\n",
    "            step += 1\n",
    "            if step%100 == 0:\n",
    "                print_top_words(model.beta.weight.T.to('cpu').detach().numpy(), list(word2id.keys()),n)\n",
    "\n",
    "        print('Epoch: ', '{:03d} loss: {:.3f}'.format(epoch + 1, np.mean(train_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04195298",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from NQTM_torch import NQTM\n",
    "from short_text_vae import Model\n",
    "import config_911 as config\n",
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6bbf5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config, vocab_X, mask, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6731f066",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (5119) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-505ca2f84c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#x=T(bow_matrix[0:2]).to(torch.float32).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#theta=model.encoder(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-038258cc179a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, config, optimizer, n)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mK_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mkl_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmle_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_omega\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_kl\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkl_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmle_loss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss_topic\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK_d\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/short_text_vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_input, lengths_X, w_omega, decoder_input, tau, beam_width, theta, z_seq, validation)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m#Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnqtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mloss_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnqtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_omega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#topic側のloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mz_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NQTM_torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, w_omega)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0m_n_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#b*vocab...??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mnegative_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_omega\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_n_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_recon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#*は要素せきなのでb*vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_encoding_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_recon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnegative_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#バッチ平均でスカラー\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_encoding_error\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquantization_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (5119) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = Model(config, vocab_X, mask, device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "train(model, train_dataloader, config, optimizer,20)\n",
    "#x=T(bow_matrix[0:2]).to(torch.float32).to(device)\n",
    "#theta=model.encoder(x)\n",
    "#theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "87cf26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "views coulter exceeds wel hillary mayors mayor guess sheikh msg achievement mirecount alexander wore accessible concession thugs stopping martin acts\n",
      "cuban democratic rejection serving utterly losses powerful crap chomsky lifting cuba products swamp doomed obamal class flint wealthy minori party\n",
      "terrorist butter extends army champions advocates migrants doubles girl <unk> kill assaults gene arriving priests il porn uni terror injured\n",
      "foreign vp kanye policy navarro allies blasts biafra queue selects retreat lou entanglements embassies peters kremlin uncharted shadow philippines cables\n",
      "uncovers wi flash flight forces jason sandy baldwin ivanka nude seized dworkin privately published pushes alec joy articles megyn nasa\n",
      "grandkids ratings exsists disbarred judges dni statistics tarmac reporter cia counselor amazing enthusiasm favourite becomes russia whisperer perfectly probe defecting\n"
     ]
    }
   ],
   "source": [
    "print_top_words(model.beta.weight.T.to('cpu').detach().numpy(), list(word2id.keys()),20)#replacementをFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c896068f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_top_words() missing 1 required positional argument: 'n_top_words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-657-c02437fd4e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#replacementをTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_top_words() missing 1 required positional argument: 'n_top_words'"
     ]
    }
   ],
   "source": [
    "print_top_words(model.beta.weight.T.to('cpu').detach().numpy(), vocab)#replacementをTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "efc13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = './NQTM/output/my_research/theta_K6_1th.npy'\n",
    "path = './NQTM/output/my_research/E_K6_1th.npy'\n",
    "E_tf = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "5c3382c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46060923, 0.10432205, 0.09942947, 0.10772838, 0.12851502,\n",
       "        0.09787384],\n",
       "       [0.1135954 , 0.44847798, 0.10744204, 0.11407465, 0.11449641,\n",
       "        0.10668501],\n",
       "       [0.1282088 , 0.11155075, 0.43263865, 0.1090094 , 0.10437302,\n",
       "        0.11207238],\n",
       "       [0.12951666, 0.12214497, 0.11223035, 0.41870385, 0.10767268,\n",
       "        0.1107961 ],\n",
       "       [0.13684861, 0.11960936, 0.09970406, 0.11118038, 0.44539905,\n",
       "        0.08983887],\n",
       "       [0.1407266 , 0.12159041, 0.10690624, 0.12019165, 0.11229575,\n",
       "        0.4075454 ]], dtype=float32)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f0751959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14383471, 0.29047459, 0.16029118, 0.18976444, 0.0796748 ,\n",
       "       0.13596028])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "413df711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04611887, 0.38681975, 0.03866256, 0.03293198, 0.02508899,\n",
       "       0.47037786])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_tf[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "0ddbaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_dataloader):\n",
    "    batch = batch.to(device)\n",
    "    theta_torch = model.encoder(batch)\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "acdc5ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3869409 , 0.08801629, 0.08779786, 0.087264  , 0.08757392,\n",
       "       0.08765152, 0.08736151, 0.08739404], dtype=float32)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_torch.to('cpu').detach().numpy()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "6739e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_torch.to('cpu').detach().numpy()[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "83e0b43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.5311, 0.1068, 0.1309, 0.0782, 0.0873, 0.0779],\n",
       "        [0.1155, 0.4706, 0.1320, 0.1044, 0.0705, 0.1063],\n",
       "        [0.1079, 0.1046, 0.5217, 0.0949, 0.0814, 0.0857],\n",
       "        [0.0849, 0.0981, 0.1661, 0.4318, 0.1278, 0.0865],\n",
       "        [0.1134, 0.1129, 0.1079, 0.0883, 0.4558, 0.1231],\n",
       "        [0.0969, 0.0916, 0.1204, 0.1241, 0.1058, 0.4635]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topic_dis_quant._E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "87e42a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topic_dis_quant._E.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
